{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is used to plot mnist images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_imgs(imgs,l1=4,l2=5,s1=6,s2=6):\n",
    "    \"\"\"    Plot images    \"\"\"\n",
    "    plt.rcParams['figure.figsize']=(s1,s2)\n",
    "    imgs=imgs.reshape([-1,28,28])\n",
    "    g, ax = plt.subplots(l1,l2)\n",
    "    for i in range(l1):\n",
    "        for j in range(l2):\n",
    "            a=i*l1+j\n",
    "            if(a>=imgs.shape[0]):\n",
    "                break\n",
    "            ax[i][j].imshow(imgs[a,:,:],cmap='summer')\n",
    "            ax[i][j].set_xticks([])\n",
    "            ax[i][j].set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "$100$ MNIST images have been stored as \"mnist_100_28x28_p0.5.npy\".\n",
    "\n",
    "Each image contains $n=28\\times 28=784$ pixels, each of which takes value $0$ or $1$.\n",
    "\n",
    "In our settings, each image is viewed as a product state in the Hilbert space of  dimension $2^n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=784 # number of qubits\n",
    "m=20 # m images\n",
    "data=np.load(\"mnist_100_28x28_p0.5.npy\")\n",
    "data=data[:m,:,:]\n",
    "data=torch.LongTensor(data)\n",
    "data=data.view(-1,784) # m images, each of which is reshaped into a vector of length 784\n",
    "show_imgs(data,2,10,10,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPS initialization\n",
    "Define the mps, which is a list of 3-way tensors containing random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dmax=30 # maximum bond dimension\n",
    "bond_dims=[Dmax for i in range(n-1)]+[1]\n",
    "tensors= [ torch.randn(bond_dims[i-1],2,bond_dims[i]) for i in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the bond dimensions and tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"There are len(tensors) tensors\")\n",
    "print(bond_dims)\n",
    "print(tensors[5].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: does the contration with one image give a probability of the image? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canonicalization using QR decompositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def orthogonalize(site,going_right):\n",
    "    dl=bond_dims[site-1] # left bond dimension\n",
    "    d=bond_dims[site]   # current bond dimension\n",
    "    if(going_right):\n",
    "        #print(\"site=\",site,tensors[site].shape,\"dl=\",dl,\"d=\",d)\n",
    "        A=tensors[site].view(dl*2,d) # A is a matrix unfolded from the current tensor\n",
    "        Q,R=torch.qr(A)\n",
    "        R/=R.norm() # devided by norm \n",
    "        tensors[site] = Q.contiguous().view(dl,2,-1)\n",
    "        tensors[site+1] = (R@tensors[site+1].view(d,-1)).view(-1,2,bond_dims[site+1])\n",
    "        bond_dims[site] = Q.shape[1] # economy QR, so the right dimension could be either dl or d\n",
    "    else: # going left\n",
    "        A=tensors[site].view(dl,d*2).t()\n",
    "        Q,R=torch.qr(A)\n",
    "        R/=R.norm() \n",
    "        tensors[site]=Q.t().contiguous().view(-1,2,d)\n",
    "        tensors[site-1] = (tensors[site-1].view(-1,dl)@R.t()).view(bond_dims[site-2],2,-1)\n",
    "        bond_dims[site-1] = Q.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPS left canonicalization\n",
    "Canonicalization gives several advantages. \n",
    "\n",
    "First, it make the partition function of the model equals to $1$. \n",
    "\n",
    "Second, the isometries have condition number $1$, preserving very well the computation precisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in range(n-1):\n",
    "    orthogonalize(site,True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors[783].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canonicalization changes the bond dimensions, to see it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(bond_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now contracting mps with one image gives the probability amplitude of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_psi():\n",
    "    psi=torch.ones([m,1,1])\n",
    "    for site in range(n):\n",
    "        psi = psi @ tensors[site][:,data[:,site],:].permute(1,0,2)\n",
    "    return(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_samples(ns):\n",
    "    samples=np.zeros([ns,n])\n",
    "    for site in range(n-1):# left canonicalize\n",
    "        orthogonalize(site,True) \n",
    "    for s in range(ns):\n",
    "        vec=torch.ones(1,1)\n",
    "        for site in range(n-1,-1,-1):\n",
    "            vec = (tensors[site].view(-1,bond_dims[site])@vec).view(-1,2)\n",
    "            p0 = vec[:,0].norm()**2/ (vec.norm()**2)\n",
    "            x = (0 if np.random.rand() < p0 else 1)\n",
    "            vec = vec[:,x]\n",
    "            samples[s][site]=x\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize cache for MPS\n",
    "Computing probability of a image consists of contracting bonds from the first tensor to the last tensor. Lots of computation results can be re-used in the future computations, so we would like to store the contraction results in the cache.\n",
    "Notice that the cache is for all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache=[] \n",
    "cache.append( torch.ones([m,1,1])) # The initial elements, all images have cache 1\n",
    "for site in range(n-1):\n",
    "    B=cache[site] @ tensors[site][:,data[:,site],:].permute(1,0,2)\n",
    "    B /= B.abs().max()\n",
    "    cache.append(  B  ) # batched matrix multiplications\n",
    "cache.append( torch.ones(m,1,1)) # the last element, matrix [1,1] for all images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of the case is $n+1$. In the caceh, for an image, each pixel has a correponding vector, denoting the temporary results in tensor contractions (from left to right or from right to left).\n",
    "Let us look at the content of cache for image alpha=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha=1 # the image 1\n",
    "print(\"cache site 1 \",cache[0][alpha])\n",
    "print(\"cache site 2 \",cache[1][alpha])\n",
    "print(\"cache site 3 \",cache[2][alpha])\n",
    "print(\"cache site 4 \",cache[3][alpha])\n",
    "print(\"cache site 5 \",cache[4][alpha])\n",
    "print(\"cache site 6 \",cache[4][alpha])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the probability amplitude $\\psi$ for images can be obtained by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi=get_psi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us output the probablity for an image, which equals $|\\psi|^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Probability of generating image 1 = %.3f\"%(psi*psi)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hey, the probability is $0$, what is wrong?**  \n",
    "\n",
    "Because the space is too large and the model is randomly initialized!\n",
    "\n",
    "Actually the purpose of training is exactly to increase the probability (or equivalently, log probability) of given images. This is the so-called *maximum likelihood learning*\n",
    "\n",
    "The basic procedure is sweeping back and force, from right to left, then from left to right. During each sweep, the visited tensor is updated according to the *gradients* of the log-probability with respect to tensor elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate=0.08\n",
    "for epoch in range(30):\n",
    "    # one sweep, from right to left, then from left to right\n",
    "    going_right=False\n",
    "    for site in [i for i in range(n-1,0,-1)]+[i for i in range(n-1)]:\n",
    "        # to update tensors[site] which is a 3-way tensor of size [dl,2,dr]\n",
    "        sys.stdout.write(\"\\r Epoch #%d, site #%d / %d           \"%(epoch, site+1,n)); sys.stdout.flush()\n",
    "        if(site==0): going_right=True\n",
    "        gradients = torch.zeros_like(tensors[site])\n",
    "        for i in [0,1]: # the pixel could be either 0 or 1\n",
    "            idx=(data[:,site]==i).nonzero().type(torch.LongTensor).squeeze() # this returns indices of non-zero elements\n",
    "            if(idx.numel()==0): continue\n",
    "            left_vec = cache[site][idx,:,:] # a vector on the left of the site\n",
    "            right_vec = cache[site+1][idx,:,:] # a vector on the right of the site\n",
    "            A=tensors[site][:,data[idx,site],:]\n",
    "            if(idx.numel()==1): \n",
    "                A=A.view(A.shape[0],1,A.shape[1])\n",
    "                left_vec=left_vec.view(1,left_vec.shape[0],left_vec.shape[1])\n",
    "                right_vec=right_vec.view(1,right_vec.shape[0],right_vec.shape[1])\n",
    "            psi = left_vec @ A.permute(1,0,2) @right_vec # probability amplitude\n",
    "            gradients[:,i,:] = torch.sum(left_vec.permute(0,2,1) @ right_vec.permute(0,2,1) / psi,0) \n",
    "        gradients = 2.0*(gradients/m-tensors[site])  \n",
    "        tensors[site] += learning_rate * gradients/gradients.norm()\n",
    "        canonicalize(site,going_right)\n",
    "        if(going_right):\n",
    "            cache[site+1] = cache[site] @ tensors[site][:,data[:,site],:].permute(1,0,2)\n",
    "            cache[site+1] /= cache[site+1].abs().max()\n",
    "        else:\n",
    "            cache[site] = tensors[site][:,data[:,site],:].permute(1,0,2) @ cache[site+1]\n",
    "            cache[site] /= cache[site].abs().max()\n",
    "    psi=get_psi()\n",
    "    tensors_bak=tensors.copy()\n",
    "    sys.stdout.write(\"NLL=%.3f, LowerBound=%.3f\\n\"%(-torch.mean(torch.log(psi*psi)),math.log(m)))\n",
    "    sys.stdout.write(\"  generating samples...\")\n",
    "    imgs=gen_samples(30)\n",
    "    show_imgs(imgs,2,15,15,2)\n",
    "    tensors=tensors_bak.copy()\n",
    "    input(\"Press Enter to continue  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
